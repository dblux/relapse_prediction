{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dblux/anaconda3/envs/r-1/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanorama\n",
    "import scipy.sparse as sparse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39 114 156 187 230 263 290 345 405]\n"
     ]
    }
   ],
   "source": [
    "# # Equal-sized batches\n",
    "# num_batches = 6\n",
    "\n",
    "# # Odd-sized batches (MAQC)\n",
    "# odd_batches = [10,9,9,8,8,7]\n",
    "# odd_cutpoints = np.cumsum(odd_batches)[:-1]\n",
    "\n",
    "# log_maqc = np.loadtxt(\"data/scanorama/log_maqc.tsv\")\n",
    "# print(log_maqc[:5,:5])\n",
    "# print(log_maqc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 54675)\n",
      "(10, 54675)\n",
      "(10, 54675)\n",
      "(10, 54675)\n",
      "(10, 54675)\n",
      "(10, 54675)\n"
     ]
    }
   ],
   "source": [
    "# Transpose array into samples x genes\n",
    "list_arr = np.split(np.transpose(log_maqc), num_batches, axis = 0)\n",
    "# # When batches are in odd proportions\n",
    "# list_arr = np.split(np.transpose(log_maqc), odd_cutpoints, axis = 0)\n",
    "for elem in list_arr:\n",
    "    print(elem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "file = \"data/scanorama/probeset_names.txt\"\n",
    "with open(file, \"r\") as f:\n",
    "    list_genes = f.readlines()\n",
    "\n",
    "list_genes = [gene.strip() for gene in list_genes]\n",
    "# Repeat list of genes for each batch\n",
    "list_list_genes = [list_genes] * num_batches\n",
    "print(len(list_list_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54675 genes among all datasets\n",
      "[[0.  1.  0.3 1.  0.5 0.4]\n",
      " [0.  0.  1.  0.8 0.9 0.9]\n",
      " [0.  0.  0.  0.9 1.  1. ]\n",
      " [0.  0.  0.  0.  0.8 1. ]\n",
      " [0.  0.  0.  0.  0.  0.6]\n",
      " [0.  0.  0.  0.  0.  0. ]]\n",
      "Processing datasets (3, 5)\n",
      "Processing datasets (2, 5)\n",
      "Processing datasets (2, 4)\n",
      "Processing datasets (1, 2)\n",
      "Processing datasets (0, 3)\n",
      "Processing datasets (0, 1)\n",
      "Processing datasets (2, 3)\n",
      "Processing datasets (1, 5)\n",
      "Processing datasets (1, 4)\n",
      "Processing datasets (3, 4)\n",
      "Processing datasets (1, 3)\n",
      "Processing datasets (4, 5)\n",
      "Processing datasets (0, 4)\n",
      "Processing datasets (0, 5)\n",
      "Processing datasets (0, 2)\n"
     ]
    }
   ],
   "source": [
    "# # Integration (Returns SVD embeddings)\n",
    "# integrated, genes = scanorama.integrate(list_arr, list_list_genes)\n",
    "\n",
    "# Batch correction.\n",
    "list_corrected_arr, gene_colnames = scanorama.correct(list_arr, list_list_genes, knn = 10)\n",
    "\n",
    "# # Integration and batch correction.\n",
    "# integrated, corrected, genes = scanorama.correct(list_arr, list_list_genes, return_dimred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54675, 60)\n",
      "                  0         1         2         3         4\n",
      "1007_s_at  0.006693  0.006478  0.006609  0.006641  0.006574\n",
      "1053_at    0.006494  0.006402  0.006388  0.006498  0.006433\n",
      "117_at     0.000157  0.000227  0.000000  0.000000  0.000001\n",
      "121_at     0.005231  0.005113  0.005167  0.005188  0.005151\n",
      "1255_g_at  0.000000  0.000000  0.000000  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "corrected_arr = sparse.vstack(list_corrected_arr)\n",
    "corrected_arr1 = sparse.csr_matrix.transpose(corrected_arr)\n",
    "print(corrected_arr1.shape)\n",
    "# Replace negative values with 0\n",
    "corrected_arr1[corrected_arr1 < 0] = 0\n",
    "corrected_df = pd.DataFrame(corrected_arr1.toarray())\n",
    "# Name rownames of df with output list from scanorama\n",
    "corrected_df.index = gene_colnames\n",
    "# Rows of genes not ordered the same way as input\n",
    "# Sort rows according to initial rownames\n",
    "corrected_df1 = corrected_df.reindex(list_genes)\n",
    "print(corrected_df1.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_df1.to_csv(\"data/scanorama/scanorama_data_k10.tsv\",\n",
    "                     sep = \"\\t\", header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function correct in module scanorama.scanorama:\n",
      "\n",
      "correct(datasets_full, genes_list, return_dimred=False, batch_size=5000, verbose=2, ds_names=None, dimred=100, approx=True, sigma=15, alpha=0.1, knn=20, return_dense=False, hvg=None, union=False, geosketch=False, geosketch_max=20000, seed=0)\n",
      "    Integrate and batch correct a list of data sets.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    datasets_full : `list` of `scipy.sparse.csr_matrix` or of `numpy.ndarray`\n",
      "        Data sets to integrate and correct.\n",
      "    genes_list: `list` of `list` of `string`\n",
      "        List of genes for each data set.\n",
      "    return_dimred: `bool`, optional (default: `False`)\n",
      "        In addition to returning batch corrected matrices, also returns\n",
      "        integrated low-dimesional embeddings.\n",
      "    batch_size: `int`, optional (default: `5000`)\n",
      "        The batch size used in the alignment vector computation. Useful when\n",
      "        correcting very large (>100k samples) data sets. Set to large value\n",
      "        that runs within available memory.\n",
      "    verbose: `bool` or `int`, optional (default: 2)\n",
      "        When `True` or not equal to 0, prints logging output.\n",
      "    ds_names: `list` of `string`, optional\n",
      "        When `verbose=True`, reports data set names in logging output.\n",
      "    dimred: `int`, optional (default: 100)\n",
      "        Dimensionality of integrated embedding.\n",
      "    approx: `bool`, optional (default: `True`)\n",
      "        Use approximate nearest neighbors, greatly speeds up matching runtime.\n",
      "    sigma: `float`, optional (default: 15)\n",
      "        Correction smoothing parameter on Gaussian kernel.\n",
      "    alpha: `float`, optional (default: 0.10)\n",
      "        Alignment score minimum cutoff.\n",
      "    knn: `int`, optional (default: 20)\n",
      "        Number of nearest neighbors to use for matching.\n",
      "    return_dense: `bool`, optional (default: `False`)\n",
      "        Return `numpy.ndarray` matrices instead of `scipy.sparse.csr_matrix`.\n",
      "    hvg: `int`, optional (default: None)\n",
      "        Use this number of top highly variable genes based on dispersion.\n",
      "    seed: `int`, optional (default: 0)\n",
      "        Random seed to use.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    corrected, genes\n",
      "        By default (`return_dimred=False`), returns a two-tuple containing a\n",
      "        list of `scipy.sparse.csr_matrix` each with batch corrected values,\n",
      "        and a single list of genes containing the intersection of inputted\n",
      "        genes.\n",
      "    \n",
      "    integrated, corrected, genes\n",
      "        When `return_dimred=False`, returns a three-tuple containing a list\n",
      "        of `numpy.ndarray` with integrated low dimensional embeddings, a list\n",
      "        of `scipy.sparse.csr_matrix` each with batch corrected values, and a\n",
      "        a single list of genes containing the intersection of inputted genes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scanorama.correct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
